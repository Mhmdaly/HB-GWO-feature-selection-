# HB-GWO Feature Selection

This repository contains the implementation of the **Hybrid Butterfly-Grey Wolf Optimization (HB-GWO)** algorithm for feature selection in high-dimensional datasets.

## ğŸ“¦ Features
- Hybrid global-local search via BOA and GWO
- Adaptive switching strategy
- Multi-classifier evaluation (Random Forest, SVM, XGBoost, MLP)
- Balanced metrics (F1, AUC-ROC)
- Sensitivity analysis and Optuna tuning
- Real-world scalability validation (e.g., RNA-seq with >100k features)

## ğŸ› ï¸ Requirements
- Python 3.11
- NumPy
- scikit-learn
- matplotlib
- optuna
- pandas
- seaborn

## ğŸš€ Running the Code
```bash
python main.py
```

## ğŸ“Š Parameters
Key algorithm parameters (all customizable):

- **BOA**: `c=0.01`, `a=0.1`, `p=0.8`
- **GWO**: Dynamic A and C vectors
- **General**: Population=30, Iterations=200, Î»=0.75, Î±=0.65

## ğŸ“‚ Structure
- `main.py` â€“ Main algorithm config and structure
- `README.md` â€“ Documentation and setup guide

## ğŸ“œ License
MIT License

## ğŸ“« Contact
For questions or collaborations, reach out to [mohammed-alysalem@eru.edu.eg](mailto:mohammed-alysalem@eru.edu.eg)
